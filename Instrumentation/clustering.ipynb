{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132c98d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import CubicSpline\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f02e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from fcmeans import FCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390753d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "from scipy.stats import skew\n",
    "\n",
    "colors = ['r', 'g', 'b']\n",
    "labels_str = ['Slug', 'Intermittent', 'Annular']\n",
    "markers = ['o', '^', 's']  # circle, triangle, square\n",
    "\n",
    "df = pd.read_csv('volume-average-rfile.csv')\n",
    "df['time'] = df['time'] * 0.01\n",
    "\n",
    "C_liquid = 1.113e-10 * 1.51 * (10*10)/10\n",
    "C_gas = 1.113e-10 * 1.000494 * (10*10)/10\n",
    "\n",
    "def convert_to_capacitance(void_fraction, C_l, C_g):\n",
    "    return C_l - (void_fraction * (C_l - C_g))\n",
    "\n",
    "df['capacitance'] = df['Volume fraction'].apply(lambda x: convert_to_capacitance(x, C_liquid, C_gas))\n",
    "\n",
    "def create_intervals(data, interval_size):\n",
    "    intervals = []\n",
    "    stats = []\n",
    "\n",
    "    for i in range(0, len(data) - interval_size + 1, interval_size):\n",
    "        interval = data.iloc[i:i+interval_size]\n",
    "\n",
    "        mean = interval['capacitance'].mean()\n",
    "        variance = interval['capacitance'].var()\n",
    "        skewness = skew(interval['capacitance'])\n",
    "        kurtosis = moment(interval['capacitance'], moment=4)\n",
    "\n",
    "        stats.append([mean, variance, kurtosis])\n",
    "\n",
    "    return np.array(stats)\n",
    "\n",
    "# After reading and initial processing of the data\n",
    "# Add this code before the interpolation section\n",
    "\n",
    "# Split data into flow regimes and filter annular data\n",
    "def categorize_flow(time):\n",
    "    if time <= 0.85:\n",
    "        return 'Slug'\n",
    "    elif time <= 1.5:\n",
    "        return 'Intermittent'\n",
    "    else:\n",
    "        return 'Annular'\n",
    "\n",
    "# Split data into flow regimes\n",
    "df['flow_regime'] = df['time'].apply(categorize_flow)\n",
    "slug_data = df[df['flow_regime'] == 'Slug']\n",
    "intermittent_data = df[df['flow_regime'] == 'Intermittent']\n",
    "\n",
    "# Filter annular data up to specific time (e.g., time <= 5.0)\n",
    "max_annular_time = 3.5  # You can adjust this value\n",
    "annular_data = df[(df['flow_regime'] == 'Annular') & (df['time'] <= max_annular_time)]\n",
    "\n",
    "# Interpolate slug and intermittent data\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern\n",
    "\n",
    "def interpolate_selected_data(original_df, n_points_between):\n",
    "    # Try a more flexible kernel\n",
    "    kernel = 1.0 * RBF(length_scale=0.2) + WhiteKernel(noise_level=0.05)\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, optimizer='fmin_l_bfgs_b', random_state=0)\n",
    "\n",
    "    X = original_df['time'].values.reshape(-1, 1)\n",
    "    y = original_df['Volume fraction'].values\n",
    "    gpr.fit(X, y)\n",
    "\n",
    "    # Create new time points\n",
    "    new_times = []\n",
    "    for i in range(len(X)-1):\n",
    "        t_start = X[i][0]\n",
    "        t_end = X[i+1][0]\n",
    "        t_between = np.linspace(t_start, t_end, n_points_between + 2)[1:-1]\n",
    "        new_times.extend(t_between)\n",
    "    all_times = np.sort(np.concatenate([X.flatten(), np.array(new_times)]))\n",
    "\n",
    "    predictions, std = gpr.predict(all_times.reshape(-1, 1), return_std=True)\n",
    "\n",
    "    df_pred = pd.DataFrame({\n",
    "        'time': all_times,\n",
    "        'Volume fraction': predictions,\n",
    "        'uncertainty': std\n",
    "    })\n",
    "    df_pred['capacitance'] = df_pred['Volume fraction'].apply(\n",
    "        lambda x: convert_to_capacitance(x, C_liquid, C_gas)\n",
    "    )\n",
    "    return df_pred\n",
    "\n",
    "\n",
    "# Interpolate slug and intermittent regions\n",
    "slug_interpolated = interpolate_selected_data(slug_data, 2) # 9\n",
    "intermittent_interpolated = interpolate_selected_data(intermittent_data, 2) # 12\n",
    "\n",
    "# Add capacitance to annular data if not already present\n",
    "if 'capacitance' not in annular_data.columns:\n",
    "    annular_data['capacitance'] = annular_data['Volume fraction'].apply(\n",
    "        lambda x: convert_to_capacitance(x, C_liquid, C_gas)\n",
    "    )\n",
    "\n",
    "df_interpolated = pd.concat([\n",
    "    slug_interpolated,\n",
    "    intermittent_interpolated,\n",
    "    annular_data[['time', 'Volume fraction', 'capacitance', 'flow_regime']]\n",
    "]).sort_values('time').reset_index(drop=True)\n",
    "\n",
    "df_combined = pd.concat([\n",
    "    df[['time', 'Volume fraction', 'capacitance', 'flow_regime']],\n",
    "    df_interpolated[['time', 'Volume fraction', 'capacitance', 'flow_regime']]\n",
    "]).sort_values('time').reset_index(drop=True)\n",
    "\n",
    "# Create features from combined dataset\n",
    "features_combined = create_intervals(df_combined, 20)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_combined)\n",
    "\n",
    "# Fit clustering model on combined features\n",
    "fcm = FCM(n_clusters=3)\n",
    "fcm.fit(features_scaled)\n",
    "\n",
    "def relabel_clusters(labels, features_scaled):\n",
    "    # Get mean capacitance (first feature) for each cluster\n",
    "    cluster_means = []\n",
    "    for i in range(3):\n",
    "        cluster_points = features_scaled[labels == i]\n",
    "        mean_capacitance = np.mean(cluster_points[:, 0])  # First feature is mean capacitance\n",
    "        cluster_means.append((i, mean_capacitance))\n",
    "\n",
    "    # Sort clusters by mean capacitance\n",
    "    # Slug has lowest capacitance, Annular has highest\n",
    "    sorted_clusters = sorted(cluster_means, key=lambda x: x[1])\n",
    "\n",
    "    # Create mapping from original labels to correct order\n",
    "    mapping = {\n",
    "        sorted_clusters[0][0]: 2,  # Slug\n",
    "        sorted_clusters[1][0]: 1,  # Intermittent\n",
    "        sorted_clusters[2][0]: 0   # Annular\n",
    "    }\n",
    "\n",
    "    # Relabel the clusters\n",
    "    new_labels = np.array([mapping[label] for label in labels])\n",
    "    return new_labels\n",
    "\n",
    "# After FCM clustering, relabel the clusters\n",
    "labels = relabel_clusters(fcm.u.argmax(axis=1), features_scaled)\n",
    "\n",
    "# Define common style parameters\n",
    "plt.style.use('default')\n",
    "\n",
    "# Define colors and markers\n",
    "colors = ['red', 'green', 'blue']  # Standard RGB colors\n",
    "labels_str = ['Slug', 'Intermittent', 'Annular']\n",
    "markers = ['o', '^', 's']  # circle, triangle, square\n",
    "\n",
    "# Common font sizes\n",
    "TITLE_SIZE = 16\n",
    "AXIS_LABEL_SIZE = 14\n",
    "LEGEND_SIZE = 12\n",
    "\n",
    "# 3D Plot (fig1)\n",
    "fig1 = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig1.add_subplot(111, projection='3d')\n",
    "\n",
    "for i in range(3):\n",
    "    cluster_points = features_scaled[labels == i]\n",
    "    ax1.scatter(cluster_points[:, 0],\n",
    "              cluster_points[:, 1],\n",
    "              cluster_points[:, 2],\n",
    "              marker=markers[i],\n",
    "              facecolors='none',\n",
    "              edgecolors=colors[i],\n",
    "              s=100,\n",
    "              linewidth=1.5,\n",
    "              label=labels_str[i])\n",
    "\n",
    "ax1.set_xlabel('Normalized Mean Capacitance', fontsize=AXIS_LABEL_SIZE)\n",
    "ax1.set_ylabel('Normalized Variance', fontsize=AXIS_LABEL_SIZE)\n",
    "ax1.set_zlabel('Normalized Kurtosis', fontsize=AXIS_LABEL_SIZE)\n",
    "ax1.legend(fontsize=LEGEND_SIZE)\n",
    "ax1.set_title('3D View of Flow Patterns', fontsize=TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mean vs Variance Plot (fig2)\n",
    "fig2 = plt.figure(figsize=(10, 8))\n",
    "ax2 = fig2.add_subplot(111)\n",
    "\n",
    "for i in range(3):\n",
    "    cluster_points = features_scaled[labels == i]\n",
    "    ax2.scatter(cluster_points[:, 0],\n",
    "               cluster_points[:, 1],\n",
    "               marker=markers[i],\n",
    "               facecolors='none',\n",
    "               edgecolors=colors[i],\n",
    "               s=100,\n",
    "               linewidth=1.5,\n",
    "               label=labels_str[i])\n",
    "\n",
    "ax2.set_xlabel('Normalized Mean Capacitance', fontsize=AXIS_LABEL_SIZE)\n",
    "ax2.set_ylabel('Normalized Variance', fontsize=AXIS_LABEL_SIZE)\n",
    "ax2.legend(fontsize=LEGEND_SIZE)\n",
    "ax2.set_title('Mean vs Variance View of Flow Patterns', fontsize=TITLE_SIZE)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Variance vs Kurtosis Plot (fig3)\n",
    "fig3 = plt.figure(figsize=(10, 8))\n",
    "ax3 = fig3.add_subplot(111)\n",
    "\n",
    "for i in range(3):\n",
    "    cluster_points = features_scaled[labels == i]\n",
    "    ax3.scatter(cluster_points[:, 1],\n",
    "               cluster_points[:, 2],\n",
    "               marker=markers[i],\n",
    "               facecolors='none',\n",
    "               edgecolors=colors[i],\n",
    "               s=100,\n",
    "               linewidth=1.5,\n",
    "               label=labels_str[i])\n",
    "\n",
    "ax3.set_xlabel('Normalized Variance', fontsize=AXIS_LABEL_SIZE)\n",
    "ax3.set_ylabel('Normalized Kurtosis', fontsize=AXIS_LABEL_SIZE)\n",
    "ax3.legend(fontsize=LEGEND_SIZE)\n",
    "ax3.set_title('Variance vs Kurtosis View of Flow Patterns', fontsize=TITLE_SIZE)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figures with black background\n",
    "fig1.savefig('3d_plot.png', bbox_inches='tight', pad_inches=0.5, dpi=300,\n",
    "              edgecolor='none')\n",
    "fig2.savefig('mean_variance_plot.png', bbox_inches='tight', pad_inches=0.5, dpi=300,\n",
    "              edgecolor='none')\n",
    "fig3.savefig('variance_kurtosis_plot.png', bbox_inches='tight', pad_inches=0.5, dpi=300,\n",
    "             edgecolor='none')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "def categorize_flow(time):\n",
    "    if time <= 0.85:\n",
    "        return 'Slug'\n",
    "    elif time <= 1.5:\n",
    "        return 'Intermittent'\n",
    "    else:\n",
    "        return 'Annular'\n",
    "\n",
    "# Apply categorization to the time data\n",
    "df['flow_regime'] = df['time'].apply(categorize_flow)\n",
    "\n",
    "\n",
    "# Reset matplotlib style to default (light mode)\n",
    "plt.style.use('default')\n",
    "\n",
    "# Define larger font sizes\n",
    "TITLE_SIZE = 20\n",
    "LABEL_SIZE = 16\n",
    "LEGEND_SIZE = 14\n",
    "PERCENT_SIZE = 14\n",
    "\n",
    "# Define consistent color mapping\n",
    "flow_colors = {\n",
    "    'Annular': 'lightblue',\n",
    "    'Intermittent': 'lightgreen',\n",
    "    'Slug': 'lightcoral'\n",
    "}\n",
    "\n",
    "# Modified function for labeling with larger font size\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return f'{pct:.1f}%\\n({val:d})'\n",
    "    return lambda pct: f'$\\mathbf{{{pct:.1f}\\%}}$\\n({int(round(pct*sum(values)/100.0)):d})'\n",
    "\n",
    "# Create and save Original Data Pie Chart\n",
    "plt.figure(figsize=(12, 10))  # Increased figure size\n",
    "original_regime_counts = df['flow_regime'].value_counts()\n",
    "\n",
    "# Sort the counts to maintain consistent order\n",
    "ordered_regimes = ['Slug', 'Intermittent', 'Annular']\n",
    "ordered_counts = [original_regime_counts.get(regime, 0) for regime in ordered_regimes]\n",
    "ordered_colors = [flow_colors[regime] for regime in ordered_regimes]\n",
    "\n",
    "plt.pie(ordered_counts,\n",
    "        labels=ordered_regimes,\n",
    "        autopct=make_autopct(ordered_counts),\n",
    "        colors=ordered_colors,\n",
    "        explode=(0.05, 0.05, 0.05),\n",
    "        textprops={'fontsize': LABEL_SIZE})  # Increased label font size\n",
    "plt.title('Original Distribution of Flow Regimes', fontsize=TITLE_SIZE, pad=20, fontweight='bold')\n",
    "\n",
    "# Add legend with consistent order and larger font\n",
    "plt.legend(ordered_regimes,\n",
    "          title=\"Flow Regimes\",\n",
    "          title_fontsize=LEGEND_SIZE,  # Increased legend title font size\n",
    "          fontsize=LEGEND_SIZE-2,      # Increased legend text font size\n",
    "          loc=\"center left\",\n",
    "          bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('original_flow_regime_pie.png',\n",
    "            bbox_inches='tight',\n",
    "            dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create and save Interpolated Data Pie Chart with same formatting\n",
    "plt.figure(figsize=(12, 10))\n",
    "df_interpolated['flow_regime'] = df_interpolated['time'].apply(categorize_flow)\n",
    "interpolated_regime_counts = df_interpolated['flow_regime'].value_counts()\n",
    "\n",
    "ordered_counts_interp = [interpolated_regime_counts.get(regime, 0) for regime in ordered_regimes]\n",
    "\n",
    "plt.pie(ordered_counts_interp,\n",
    "        labels=ordered_regimes,\n",
    "        autopct=make_autopct(ordered_counts_interp),\n",
    "        colors=ordered_colors,\n",
    "        explode=(0.05, 0.05, 0.05),\n",
    "        textprops={'fontsize': LABEL_SIZE})\n",
    "plt.title('Interpolated Distribution of Flow Regimes', fontsize=TITLE_SIZE, pad=20, fontweight='bold')\n",
    "\n",
    "plt.legend(ordered_regimes,\n",
    "          title=\"Flow Regimes\",\n",
    "          title_fontsize=LEGEND_SIZE,\n",
    "          fontsize=LEGEND_SIZE-2,\n",
    "          loc=\"center left\",\n",
    "          bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('interpolated_flow_regime_pie.png',\n",
    "            bbox_inches='tight',\n",
    "            dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Print exact counts\n",
    "print(\"\\nOriginal Data Points in each regime:\")\n",
    "for regime, count in zip(ordered_regimes, ordered_counts):\n",
    "    print(f\"{regime}: {count} points\")\n",
    "\n",
    "print(\"\\nInterpolated Data Points in each regime:\")\n",
    "for regime, count in zip(ordered_regimes, ordered_counts_interp):\n",
    "    print(f\"{regime}: {count} points\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
